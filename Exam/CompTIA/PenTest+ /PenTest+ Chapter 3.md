# CompTIA® PenTest+® Certification For Dummies®, 2nd Edition

# Chapter 3: Information Gathering

Type of information collect on Org during Information Gathering Phase:

- Email Addresses and phone numbers of employees (For Social Engineering)
- Public IP addresses used by Org.
- Target systems that are up and running.
- Open ports on target systems.
- Software used on the target systems.
- Software is running in cloud or self hosted (local server on network)

#

## Looking at Information-Gathering Tools and Techniques

Divide task into 2 parts: Passive and Active Information Gathering.

- Passive: collecting public information from internet about the Org without incoking any kind of communication with the target systems. Do first. (OSINT)
- Active: polling target system to find out about the system that are up and running, open ports and software being used. (Scanning)


Crawling Websites: Phrase to describe process of using an automated tool to fetch each page in website, analyzes the page, follows any link the page refers to and then fetch those pages.

Scraping Websites: Phrase to describe process of using program or bot to extract a copy of content in website.

Manual inspection of Web links: right clicking the link and choosing inspect from the context menu, Window opens display source code used to create the link and CSS code used.

Robots.txt: A file can be placed in the root folder of the site and contains rules on how the site and its pages are to be crawled. 
- You could create a rule in the robots.txt file that disallow specific crawling application from crawling the site.

#

## Google Hacking

Google hacking: Information gathering technique which specific keywords are used to search Google or other search engines (Bing) for information on the Internet.

- `site: <website> <keyword>`: The site keyword is used to search a specific website for a keyword.
  - If you are performing security test for Wiley publishing company: you could use site: www.wiley.com password to locate the login pages on the Wiley website.
  - This could be useful if you wanted to test Wiley’s login pages against SQL injection attacks.
 
- `intitle: <keyword>`: You can use intitle keyword to search the title of a page for specific keywords.
  - If you want to find web pages that contain the word “intranet” in the title, you could use intitle: intranet.
 
- `inurl: <keyword>`: The inurl operator will search the keyword given in the URLs found in the Google database.
  - If you want to locate sites that have the word “intranet” in the URL, you could use inurl: intranet.
 
- `intext: <keyword>`: The intext operator searches a web page for specific text.
  - If you want to search my company site for pages that contain the word “video,” you could use site: dcatt.ca intext: video.
 
- `filetype: <extension>`: One of my personal favorites is the filetype operator, which you can use to find results containing a specific file type.
  - You could search the Internet for sample penetration reports by filetype: pdf penetration test report.

#

## Referencing online Cybersecurity Sources

![image](https://github.com/user-attachments/assets/ebde4933-1e24-4758-8c1f-4fedbe7d9f02)

#

## Types of Data

Password dumps: You can use tools to obtain password dumps that display usernames and password hashes for each username. 
- The username list can be fed into a dictionary attack tool or you could use a password cracker to crack the password hashes.

File metadata: You can look at the file metadata on documents downloaded from the company’s website or other sources. 
- Metadata is additional information about the file such as the program or device used to create the file, the creator of the file, and location information.

Strategic search engine analysis/enumeration: You can use specific keywords in Google to target your search and find specific data about your target.

Website archive/caching: You can view older versions of the company’s website to get additional contact information or other information that could help in an attack. 
- For example, you could use www.archive.org and search for a website to view past versions of it.

Public source-code repositories: An archive of application source code that is made available to the public. 
- The repository may contain additional information with the source code such as technical documentation and code snippets that can be used to learn more about the company’s environment.

#

## Passive Information Gathering Tools

WHOIS: Database search tool used to discover Domain Name Information and IP Addresses about Org.


#

#

## For Exam

- Tool: `wget` in linux to copy the contents of a website to local folder on your system so you can review contents offline.
- Even HTTPS is used; should inspect Secure Sockets Layer (SSL) certificates for flaws such as expiration dates and certificates that have been revoked/no longer valid.
